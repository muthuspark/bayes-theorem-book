{"title":"Introduction to A/B Testing","markdown":{"headingText":"Introduction to A/B Testing","containsRefs":false,"markdown":"\n### What is A/B Testing?\n\nA/B testing, also known as split testing, is a randomized experiment used to compare two versions of a variable (e.g., a webpage, an email subject line, an app feature) to determine which performs better.  Version A is the control, representing the current state, while version B is the variant, representing a proposed change.  Users are randomly assigned to either group A or group B, and their interactions are tracked to measure key metrics (e.g., click-through rate, conversion rate, time spent on page).  By analyzing the results, one can determine whether the variant (B) significantly outperforms the control (A).\n\n### Why Use A/B Testing?\n\nA/B testing offers a data-driven approach to making decisions about product improvements and marketing campaigns.  Its benefits include:\n\n* **Data-driven decision making:**  Relies on empirical evidence rather than intuition or guesswork.\n* **Reduced risk:**  Allows testing changes in a controlled environment before deploying them to the entire user base.\n* **Improved performance:** Identifies changes that lead to measurable improvements in key metrics.\n* **Iterative improvement:** Enables continuous optimization and refinement of products and marketing materials.\n* **Objective comparison:** Provides a quantitative assessment of the impact of different versions.\n\n\n### A/B Testing in the Context of Bayes' Theorem\n\nWhile frequentist methods are often used in A/B testing (e.g., calculating p-values), Bayesian methods offer many advantages, particularly when dealing with smaller sample sizes or prior knowledge about the variables involved.  Bayes' theorem allows us to update our beliefs about the probability of each version being superior based on the observed data.\n\nLet's consider a simple example:  We are A/B testing two website headlines.  Let $θ_A$ be the true conversion rate of headline A and $θ_B$ be the true conversion rate of headline B. We'll assume prior distributions for $θ_A$ and $θ_B$ are Beta distributions, which are conjugate priors for the binomial likelihood.  This means the posterior distribution will also be a Beta distribution, making calculations easier.\n\nLet's assume our prior beliefs are represented by Beta(1,1) distributions for both headlines, representing a uniform prior.  We observe $n_A$ conversions out of $N_A$ trials for headline A and $n_B$ conversions out of $N_B$ trials for headline B.  The likelihood function for each headline is a binomial distribution.  Using Bayes' theorem, the posterior distributions for $θ_A$ and $θ_B$ are:\n\n$P(θ_A | n_A, N_A) \\propto Beta(1 + n_A, 1 + N_A - n_A)$\n\n$P(θ_B | n_B, N_B) \\propto Beta(1 + n_B, 1 + N_B - n_B)$\n\n\nWe can then compare the posterior distributions to assess which headline is more likely to have a higher conversion rate.  For example, we can calculate the probability that $θ_B > θ_A$.\n\n```{python}\n#| echo: true\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# Prior parameters (uniform prior)\nalpha_prior = 1\nbeta_prior = 1\n\n# Observed data\nnA = 10  # Conversions for headline A\nNA = 100 # Trials for headline A\nnB = 15  # Conversions for headline B\nNB = 100 # Trials for headline B\n\n# Posterior parameters\nalphaA_post = alpha_prior + nA\nbetaA_post = beta_prior + NA - nA\nalphaB_post = alpha_prior + nB\nbetaB_post = beta_prior + NB - nB\n\n# Generate samples from posterior distributions\nsamplesA = beta.rvs(alphaA_post, betaA_post, size=10000)\nsamplesB = beta.rvs(alphaB_post, betaB_post, size=10000)\n\n# Probability that θB > θA\nprob_B_better = np.mean(samplesB > samplesA)\nprint(f\"Probability that headline B has a higher conversion rate: {prob_B_better:.3f}\")\n\n# Plot posterior distributions\nplt.figure(figsize=(10, 6))\nplt.hist(samplesA, bins=50, alpha=0.5, label='Headline A', density=True)\nplt.hist(samplesB, bins=50, alpha=0.5, label='Headline B', density=True)\nplt.xlabel('Conversion Rate')\nplt.ylabel('Density')\nplt.title('Posterior Distributions of Conversion Rates')\nplt.legend()\nplt.show()\n\n```\n\nThis Python code simulates the posterior distributions and calculates the probability that headline B is superior. The plot visually represents the comparison of the posterior distributions.  By using Bayesian methods, we obtain a probability estimate rather than just a p-value, offering a more intuitive and informative result.  Note that the choice of prior is crucial, and informative priors can be incorporated if prior knowledge exists.\n\n\n## Bayesian vs. Frequentist A/B Testing\n\n### Frequentist Approach: p-values and Hypothesis Testing\n\nThe frequentist approach to A/B testing relies on hypothesis testing.  We formulate a null hypothesis ($H_0$) that there is no difference between the two versions (e.g., $θ_A = θ_B$), and an alternative hypothesis ($H_1$) that there is a difference (e.g., $θ_A \\neq θ_B$).  We then collect data and calculate a p-value, which represents the probability of observing the data (or more extreme data) if the null hypothesis were true.  If the p-value is below a pre-determined significance level (e.g., 0.05), we reject the null hypothesis and conclude that there is a statistically significant difference between the two versions.\n\nThe frequentist approach often employs methods like z-tests or chi-squared tests for comparing proportions.  For example, a z-test for comparing two proportions would involve calculating a z-statistic:\n\n\n$z = \\frac{(\\hat{p}_A - \\hat{p}_B)}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_A} + \\frac{1}{n_B})}}$\n\nwhere $\\hat{p}_A$ and $\\hat{p}_B$ are the sample proportions for groups A and B, $n_A$ and $n_B$ are the sample sizes, and $\\hat{p}$ is the pooled sample proportion:\n\n$\\hat{p} = \\frac{n_A\\hat{p}_A + n_B\\hat{p}_B}{n_A + n_B}$\n\n\nThe p-value is then obtained from the standard normal distribution.\n\n\n### Bayesian Approach: Prior and Posterior Distributions\n\nThe Bayesian approach models the parameters of interest ($θ_A$ and $θ_B$) as random variables with probability distributions.  We start with prior distributions that represent our initial beliefs about these parameters.  Then, we update these priors based on the observed data using Bayes' theorem to obtain posterior distributions.  These posterior distributions provide a complete representation of our updated beliefs about the parameters after considering the data.\n\nFor A/B testing with binary outcomes (e.g., conversions), Beta distributions are often used as conjugate priors for binomial likelihoods.  As shown previously, the posterior distributions are also Beta distributions, making calculations relatively straightforward.  We can then compare the posterior distributions to quantify the evidence for one version being superior to the other. For example, we can calculate the probability that $P(θ_B > θ_A)$.\n\n\n### Comparing the Two Approaches: Advantages and Disadvantages\n\n| Feature          | Frequentist Approach                                     | Bayesian Approach                                          |\n|-----------------|---------------------------------------------------------|-------------------------------------------------------------|\n| **Interpretation** | P-values; significance levels; hypothesis rejection    | Probability distributions; credible intervals; posterior probabilities |\n| **Prior Information** | Does not incorporate prior knowledge                    | Incorporates prior knowledge naturally                        |\n| **Sample Size**   | Can be problematic with small sample sizes              | Performs well even with small sample sizes                   |\n| **Uncertainty**    | Provides point estimates; ignores uncertainty in estimates | Quantifies uncertainty explicitly through posterior distributions |\n| **Computational Complexity** | Often simpler computationally                          | Can be more computationally intensive for complex models      |\n\n\n### Illustrative Example: Comparing Conversion Rates\n\nLet's consider an A/B test comparing two website designs.  We use a Bayesian approach.\n\n```{python}\n#| echo: true\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import beta\n\n# Prior parameters (weakly informative priors)\nalpha_prior = 10\nbeta_prior = 10\n\n# Observed data\nnA = 50  # Conversions for design A\nNA = 500 # Trials for design A\nnB = 70  # Conversions for design B\nNB = 500 # Trials for design B\n\n# Posterior parameters\nalphaA_post = alpha_prior + nA\nbetaA_post = beta_prior + NA - nA\nalphaB_post = alpha_prior + nB\nbetaB_post = beta_prior + NB - nB\n\n\n# Generate samples from posterior distributions\nsamplesA = beta.rvs(alphaA_post, betaA_post, size=10000)\nsamplesB = beta.rvs(alphaB_post, betaB_post, size=10000)\n\n# Probability that θB > θA\nprob_B_better = np.mean(samplesB > samplesA)\nprint(f\"Probability that design B has a higher conversion rate: {prob_B_better:.3f}\")\n\n#Plot Posterior Distributions\nplt.figure(figsize=(10,6))\nplt.hist(samplesA, bins=50, alpha=0.5, label='Design A', density=True)\nplt.hist(samplesB, bins=50, alpha=0.5, label='Design B', density=True)\nplt.xlabel('Conversion Rate')\nplt.ylabel('Density')\nplt.title('Posterior Distributions of Conversion Rates')\nplt.legend()\nplt.show()\n\n```\n\nThis example demonstrates how the Bayesian approach provides a probability that design B has a higher conversion rate, offering a better understanding compared to a simple p-value from a frequentist test.  The plot visually displays the posterior distributions, highlighting the uncertainty in the estimates.  The choice of prior (here a weakly informative prior) impacts the results,  but even with weakly informative priors, the Bayesian method often provides more intuitive results, especially with limited data.\n\n\n## Bayesian A/B Testing with Python\n\n### Setting up the Problem: Defining Priors\n\nBefore implementing a Bayesian A/B test, we need to define prior distributions for the conversion rates of our two versions (A and B).  The choice of prior depends on our prior knowledge. If we have no prior knowledge, we can use a non-informative prior, such as a Beta(1,1) distribution (uniform prior), which assigns equal probability to all conversion rates between 0 and 1. If we have some prior belief about the conversion rates (e.g., based on previous A/B tests or domain expertise), we can use a more informative prior.  For example, a Beta(α, β) prior with α > 1 and β > 1 would represent a prior belief that the conversion rate is likely to be closer to α/(α+β).  It is essential to carefully consider the choice of prior, as it can influence the posterior results.\n\n\n### Implementing Bayesian A/B Testing using PyMC or similar libraries\n\nWe'll use PyMC to perform Bayesian A/B testing. PyMC is a powerful probabilistic programming library that allows for flexible model specification and efficient posterior inference using Markov Chain Monte Carlo (MCMC) methods.\n\n```{python}\n#| echo: true\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport arviz as az\n\n# Observed data\nnA = 50  # Conversions for version A\nNA = 500 # Trials for version A\nnB = 70  # Conversions for version B\nNB = 500 # Trials for version B\n\nwith pm.Model() as model:\n    # Priors (weakly informative priors)\n    theta_A = pm.Beta(\"theta_A\", alpha=10, beta=10)\n    theta_B = pm.Beta(\"theta_B\", alpha=10, beta=10)\n\n    # Likelihoods\n    obs_A = pm.Binomial(\"obs_A\", p=theta_A, n=NA, observed=nA)\n    obs_B = pm.Binomial(\"obs_B\", p=theta_B, n=NB, observed=nB)\n\n    # Difference in conversion rates\n    delta = pm.Deterministic(\"delta\", theta_B - theta_A)\n\n    # Posterior sampling\n    trace = pm.sample(2000, tune=1000, cores=1) #adjust cores as needed\n\naz.plot_posterior(trace, var_names=['theta_A', 'theta_B', 'delta'])\nplt.show()\n\n#Probability that theta_B > theta_A\nprob_B_better = np.mean(trace.posterior[\"delta\"] > 0)\nprint(f\"Probability that version B is better: {prob_B_better:.3f}\")\n\n```\n\nThis code defines a Bayesian model with Beta priors for the conversion rates and Binomial likelihoods for the observed data.  PyMC's `pm.sample()` function performs posterior inference using an MCMC algorithm (here NUTS).\n\n\n### Interpreting Posterior Distributions: Credible Intervals and Bayes Factors\n\nThe output of the PyMC model is a set of posterior samples for each parameter.  We can analyze these samples to obtain:\n\n* **Credible Intervals:**  These represent the range of values within which we are confident (e.g., 95% credible interval) the true parameter lies.  A 95% credible interval means there's a 95% probability that the true parameter value falls within that interval.\n\n* **Bayes Factors:**  These quantify the evidence for one hypothesis (e.g., $θ_B > θ_A$) against another (e.g., $θ_B ≤ θ_A$). A Bayes factor greater than 1 supports the first hypothesis.\n\n\nThe `az.plot_posterior` function displays the posterior distributions, including credible intervals. The probability that version B is better is calculated directly from the posterior samples of the difference in conversion rates (delta).\n\n\n### Visualizing Results\n\nThe `az.plot_posterior` function provides a basic visualization.  More complex visualizations can be created to look at the posterior distributions, such as:\n\n* **Histograms:** Show the distribution of posterior samples.\n* **Density Plots:** Smoother representation of the posterior distributions.\n* **Trace Plots:** Show the MCMC chains to assess convergence.\n* **Pair Plots:** Visualize correlations between parameters.\n\nThese visualizations help us understand the uncertainty associated with the estimated parameters and make informed decisions based on the Bayesian analysis.  For example, we might generate a plot showing the posterior distributions for both `theta_A` and `theta_B` alongside their 95% credible intervals, providing a visual comparison of their likely conversion rates.  A plot of the posterior distribution of `delta` helps us understand the probability of one version being superior to the other.\n\n\n## Sequential A/B Testing\n\n### Introduction to Sequential Testing\n\nSequential A/B testing allows for the analysis of results as data are collected, rather than waiting until the end of a pre-determined experiment duration or sample size.  This approach offers many advantages, particularly in situations where conducting a lengthy A/B test is costly or time-consuming.  In sequential testing, we continuously update our belief about the relative performance of the variants as new data arrive. The test can be stopped early if the evidence strongly favors one variant, saving time and resources.\n\n### Benefits of Sequential Testing\n\n* **Faster decision-making:**  Results can be analyzed and decisions made much sooner than with traditional A/B testing.\n* **Resource efficiency:**  Avoids unnecessary data collection if a clear winner emerges early.\n* **Adaptability:**  Allows for adjusting the experiment based on interim results (though this requires careful consideration to avoid bias).\n* **Reduced risk of Type I and Type II errors:**  Appropriate stopping rules can reduce both false positives (Type I errors) and false negatives (Type II errors).\n\n\n### Implementing Sequential Bayesian A/B Testing\n\nImplementing sequential Bayesian A/B testing involves continuously updating the posterior distributions of the parameters of interest as new data are observed.  We can use the same Bayesian model as before (e.g., using Beta priors and Binomial likelihoods), but instead of running the MCMC sampling only once at the end, we'll do it iteratively as new data come in.  We'll then monitor the posterior distribution of the difference between the conversion rates and use stopping rules to decide when to stop the test.\n\n\n```{python}\n#| echo: true\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Initialize data\nnA = 0\nNA = 0\nnB = 0\nNB = 0\n\n# Prior parameters\nalpha_prior = 10\nbeta_prior = 10\n\n# Sequential data arrival (simulated)\nnew_data = [(10, 100, 15, 100), (12, 100, 18, 100), (15, 100, 20, 100), (20,100,25,100)] #Simulate batches of data\n\n# Boundaries for stopping rules (example)\nupper_boundary = 1.5\nlower_boundary = -1.5\n\n\nresults = []\nfor i, batch in enumerate(new_data):\n    nA += batch[0]\n    NA += batch[1]\n    nB += batch[2]\n    NB += batch[3]\n\n    with pm.Model() as model:\n        theta_A = pm.Beta(\"theta_A\", alpha=alpha_prior+nA, beta=beta_prior+NA-nA)\n        theta_B = pm.Beta(\"theta_B\", alpha=alpha_prior+nB, beta=beta_prior+NB-nB)\n        delta = pm.Deterministic(\"delta\", theta_B - theta_A)\n        trace = pm.sample(1000, tune=500, cores=1)\n        posterior_mean = np.mean(trace.posterior['delta'])\n        results.append(posterior_mean)\n\n    print(f\"Batch {i+1}: Posterior mean of delta = {posterior_mean}\")\n\n    # Check stopping rule\n    if posterior_mean > upper_boundary or posterior_mean < lower_boundary:\n        print(f\"Stopping rule met after batch {i+1}\")\n        break\n\n\nplt.plot(results)\nplt.axhline(y=upper_boundary, color='r', linestyle='--', label='Upper Boundary')\nplt.axhline(y=lower_boundary, color='r', linestyle='--', label='Lower Boundary')\nplt.xlabel(\"Batch Number\")\nplt.ylabel(\"Posterior Mean of Delta (θB - θA)\")\nplt.title(\"Sequential Bayesian A/B Testing\")\nplt.legend()\nplt.show()\n```\n\nThis code simulates sequential data arrival and updates the posterior after each batch.  The key is setting appropriate stopping rules.\n\n\n### Stopping Rules and Boundaries\n\nVarious stopping rules can be implemented based on the posterior distribution of the difference between the parameters. Common methods include:\n\n* **Boundary-based rules:**  Define upper and lower boundaries for the posterior mean or credible intervals of the difference in parameters.  If the posterior mean crosses either boundary, the test is stopped.\n* **Bayesian posterior predictive p-values:** These quantify the probability that the observed data would occur if the two variants were identical.\n* **Expected Loss:**  Frame the decision as minimizing expected loss (e.g., cost of choosing the wrong variant).\n\nThe choice of stopping rules and boundaries is crucial, influencing the power and error rates of the test.  Tight boundaries lead to early stopping but risk making premature conclusions, whereas loose boundaries increase testing duration.   The appropriate boundaries depend on the costs associated with Type I and Type II errors.  Careful design of the stopping rules is vital to ensure the validity and efficiency of the sequential Bayesian A/B test.  The boundaries should be established before the start of the experiment to avoid biases.\n\n\n## Decision Making with Bayesian A/B Testing\n\n### Defining Success Metrics\n\nBefore conducting a Bayesian A/B test, it's essential to define clear success metrics.  These metrics quantify what constitutes a \"better\" variant. Common metrics include:\n\n* **Conversion rate:** The percentage of users who complete a desired action (e.g., purchase, signup).\n* **Click-through rate (CTR):** The percentage of users who click on a link or button.\n* **Average revenue per user (ARPU):** The average revenue generated per user.\n* **Customer lifetime value (CLTV):** The predicted total revenue generated by a customer over their entire relationship with the company.\n* **Customer churn rate:** The percentage of customers who stop using a product or service.\n\nThe choice of metric depends on the specific goals of the A/B test.  It's essential to choose a metric that directly reflects the business objectives.\n\n\n### Calculating Expected Values\n\nOnce the posterior distributions for the parameters of interest are obtained, we can calculate expected values for the success metrics under each variant.  For example, if the success metric is conversion rate, we can compute the expected conversion rate for each variant by averaging the posterior samples of the conversion rate parameters:\n\n$E[θ_A] = \\frac{1}{N_{samples}} \\sum_{i=1}^{N_{samples}} θ_{A,i}$\n\n$E[θ_B] = \\frac{1}{N_{samples}} \\sum_{i=1}^{N_{samples}} θ_{B,i}$\n\nwhere $θ_{A,i}$ and $θ_{B,i}$ are the $i$-th posterior samples for the conversion rates of variants A and B, respectively, and $N_{samples}$ is the total number of posterior samples.\n\n\nSimilarly, we can calculate expected values for other success metrics based on their posterior distributions.\n\n```{python}\n#| echo: true\nimport pymc as pm\nimport numpy as np\n\n# ... (previous code to obtain posterior samples) ...\n\n#Calculate expected values\nexpected_theta_A = np.mean(trace.posterior[\"theta_A\"])\nexpected_theta_B = np.mean(trace.posterior[\"theta_B\"])\n\nprint(f\"Expected conversion rate for variant A: {expected_theta_A:.3f}\")\nprint(f\"Expected conversion rate for variant B: {expected_theta_B:.3f}\")\n```\n\n\n### Making Decisions based on Posterior Distributions\n\nThe decision of which variant to choose can be based on many criteria:\n\n* **Expected Value:** Choose the variant with the higher expected value for the chosen success metric.\n* **Probability of Superiority:** Choose the variant that has a higher probability of having a superior value for the chosen metric (e.g.,  $P(θ_B > θ_A)$).\n* **Credible Intervals:** If the credible intervals for the two variants do not overlap significantly,  we can have more confidence in choosing the variant with the higher expected value.  Overlapping intervals suggest more uncertainty.\n\n\n### Incorporating Costs and Risks\n\nIn real-world scenarios, decisions should consider costs and risks associated with different choices:\n\n* **Cost of implementation:** The cost of deploying and maintaining each variant.\n* **Risk of failure:** The potential negative consequences of choosing the wrong variant.\n* **Opportunity cost:** The potential benefits lost by not choosing the optimal variant.\n\nWe can incorporate these factors by defining a utility function that combines the expected value of the success metric with the costs and risks.  A decision can then be made by maximizing the expected utility.\n\n\n```{python}\n#| echo: true\n#Example incorporating costs:\n\n#Assume cost of implementing variant B is higher than A\ncost_A = 0\ncost_B = 100\n\n#Expected utility calculation\nexpected_utility_A = expected_theta_A - cost_A\nexpected_utility_B = expected_theta_B - cost_B\n\nprint(f\"Expected utility for variant A: {expected_utility_A:.3f}\")\nprint(f\"Expected utility for variant B: {expected_utility_B:.3f}\")\n\nif expected_utility_B > expected_utility_A:\n    print(\"Choose variant B despite higher cost due to higher expected utility\")\nelse:\n    print(\"Choose variant A\")\n\n```\n\nThis example demonstrates a simple utility function. More complex scenarios might involve more complex functions and potentially require simulation techniques to assess risks and incorporate uncertainty more thoroughly.  The key is to ensure that the decision-making process is transparent, data-driven, and accounts for all relevant factors, including uncertainties.\n\n\n## Advanced Topics and Considerations\n\n### Dealing with Multiple Variants\n\nWhile the previous examples focused on comparing two variants (A/B testing), many situations involve comparing more than two.  This is often referred to as A/B/n testing.  Extending Bayesian methods to this scenario is straightforward conceptually, but increases computational complexity.  We can model each variant's conversion rate with its own Beta prior and likelihood, and then compare their posterior distributions.\n\nOne approach is to calculate the probability that each variant has the highest conversion rate among all variants.  Another approach is to use a hierarchical model, which assumes that the conversion rates of the different variants are drawn from a common underlying distribution. This allows for sharing information across variants and improves estimation efficiency, particularly when some variants have fewer observations.\n\n\n### Handling Non-Stationary Data\n\nThe assumption of stationary data (i.e., the conversion rates remain constant over time) is often violated in practice.  For instance, external factors like seasonality, marketing campaigns, or changes in the overall market can affect the conversion rates.  Ignoring non-stationarity can lead to inaccurate results.\n\nTo address this, we can incorporate time-dependent models. One approach is to model the conversion rates as functions of time, such as using time series models within the Bayesian framework. This allows for capturing temporal trends and estimating how conversion rates change over time. This can also help in detecting if a variant is affected differently by external changes.  Alternatively, we could segment the data by time periods and perform separate A/B tests for each period, assuming stationarity within each segment.\n\n\n### Ethical Considerations in A/B Testing\n\nEthical considerations are critical in A/B testing.  It's important to ensure:\n\n* **Fairness:**  All variants should present a reasonable user experience. Avoiding variants that are deliberately poor to highlight the positive performance of another is unethical.\n* **Transparency:**  Users should be informed about the A/B test, at least in cases where data privacy is not a major concern.\n* **Data Privacy:**  User data should be collected and used responsibly, complying with relevant regulations and privacy policies.\n* **Bias Avoidance:** Carefully design the experiment to avoid biases in user assignment and data collection.\n* **Harmful Variants:**  Variants with the potential to cause harm (e.g., misleading information, impaired usability) should be excluded from testing.\n\nThese ethical considerations should guide the entire A/B testing process, from design to interpretation and reporting of results.\n\n\n### Beyond A/B Testing: Multi-Armed Bandit Problems\n\nA/B testing involves assigning users to variants randomly. Multi-armed bandit (MAB) problems offer a more complex approach.  In MAB, the goal is to maximize the cumulative reward (e.g., total conversions) over time by dynamically allocating more users to the better-performing variants.  Unlike A/B testing, which aims to estimate the relative performance of different variants, MAB aims to find the optimal variant *during* the experiment.\n\nMany algorithms exist for solving MAB problems, including:\n\n* **Epsilon-greedy:** Exploits the currently best-performing variant most of the time, but occasionally explores other variants.\n* **Upper Confidence Bound (UCB):**  Balances exploration and exploitation by selecting variants with high uncertainty (high upper confidence bound).\n* **Thompson Sampling:**  Maintains a probability distribution for each variant's reward and samples from these distributions to choose which variant to allocate the next user to.\n\nBayesian methods are particularly well-suited for MAB problems as they naturally incorporate uncertainty.  For example, Thompson sampling maintains a posterior distribution for each variant's reward, updated as new data arrive.\n\n\n```{python}\n#| echo: true\n#Illustrative example of Thompson Sampling (simplified):\nimport random\n\nclass Bandit:\n    def __init__(self, true_win_rate):\n        self.true_win_rate = true_win_rate\n        self.alpha = 1 #Prior parameters for beta distribution\n        self.beta = 1\n\n    def pull(self):\n        return 1 if random.random() < self.true_win_rate else 0\n\n    def sample(self):\n        return np.random.beta(self.alpha, self.beta)\n\n    def update(self, x):\n        self.alpha += x\n        self.beta += 1 -x\n\n\nbandits = [Bandit(0.2), Bandit(0.5), Bandit(0.7)] #Three bandits with different win rates\nnum_trials = 1000\n\nresults = []\nfor i in range(num_trials):\n    best_bandit = max(bandits, key=lambda b: b.sample())\n    reward = best_bandit.pull()\n    best_bandit.update(reward)\n    results.append((i, reward))\n\n#Analysis of results (Further analysis required for more robust results in real-world applications)\n```\n\nThis simple example demonstrates the core idea of Thompson sampling. In a real-world application, more complex methods and more thorough analysis would be necessary.  MAB methods offer a powerful alternative to traditional A/B testing when the focus is on maximizing cumulative reward rather than solely estimating variant performance.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"},"output-file":"ab-testing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","jupyter":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"bibliography":["../../references.bib"],"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"printing","toc":true,"toc-depth":2,"include-in-header":{"text":"\\usepackage{geometry}\n\\usepackage{wrapfig}\n\\usepackage{fvextra}\n\\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n\\geometry{\n    paperwidth=6in,\n    paperheight=9in,\n    textwidth=4.5in, % Adjust this to your preferred text width\n    textheight=6.5in,  % Adjust this to your preferred text height\n    inner=0.75in,    % Adjust margins as needed\n    outer=0.75in,\n    top=0.75in,\n    bottom=1in\n}\n\\usepackage{makeidx}\n\\usepackage{tabularx}\n\\usepackage{float}\n\\usepackage{graphicx}\n\\usepackage{array}\n\\graphicspath{{diagrams/}}\n\\makeindex\n"},"include-after-body":{"text":"\\printindex\n"},"output-file":"ab-testing.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"jupyter":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"bibliography":["../../references.bib"],"documentclass":"scrreprt","lof":false,"lot":false,"float":true,"classoption":"paper=6in:9in,pagesize=pdftex,footinclude=on,11pt","fig-cap-location":"top","urlcolor":"blue","linkcolor":"black","biblio-style":"apalike","code-block-bg":"#f0f0f0","code-block-border-left":"#000000","mermaid":{"theme":"neutral"},"fontfamily":"libertinus","monofont":"Consolas","monofontoptions":["Scale=0.7"],"template-partials":["../../before-body.tex"],"indent":true},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}