{"title":"Disease Testing with Bayes' Theorem","markdown":{"headingText":"Disease Testing with Bayes' Theorem","containsRefs":false,"markdown":"\nMedical diagnosis often involves using diagnostic tests to determine the presence or absence of a disease.  Bayes' theorem provides a powerful framework for interpreting the results of these tests, accounting for the inherent uncertainties involved.\n\n### Sensitivity and Specificity\n\nSensitivity and specificity are essential characteristics of a diagnostic test.\n\n* **Sensitivity:** The probability that a test will be positive given that the patient has the disease.  Mathematically:\n\n$Sensitivity = P(Positive | Disease) = \\frac{True Positives}{True Positives + False Negatives}$\n\n* **Specificity:** The probability that a test will be negative given that the patient does not have the disease. Mathematically:\n\n$Specificity = P(Negative | No Disease) = \\frac{True Negatives}{True Negatives + False Positives}$\n\n\n### Prior and Posterior Probabilities\n\nBefore conducting a test, we have a *prior probability* of the disease, denoted as $P(Disease)$. This prior probability might be based on the prevalence of the disease in the population, or on other clinical information about the patient.\n\nAfter conducting the test, we update our belief about the probability of the disease using Bayes' theorem. This updated probability is called the *posterior probability*, denoted as $P(Disease | Positive)$ (if the test is positive) or $P(Disease | Negative)$ (if the test is negative).\n\n\n### Predictive Values (Positive and Negative)\n\n* **Positive Predictive Value (PPV):** The probability that a patient actually has the disease given a positive test result.\n\n$PPV = P(Disease | Positive) = \\frac{Sensitivity \\times P(Disease)}{Sensitivity \\times P(Disease) + (1 - Specificity) \\times (1 - P(Disease))}$\n\n* **Negative Predictive Value (NPV):** The probability that a patient does not have the disease given a negative test result.\n\n$NPV = P(No Disease | Negative) = \\frac{Specificity \\times (1 - P(Disease))}{Specificity \\times (1 - P(Disease)) + (1 - Sensitivity) \\times P(Disease)}$\n\n\n### Likelihood Ratios\n\nLikelihood ratios provide a concise way to summarize the information provided by a diagnostic test.\n\n* **Positive Likelihood Ratio (LR+):** The ratio of the probability of a positive test result given the presence of the disease to the probability of a positive test result given the absence of the disease.\n\n$LR+ = \\frac{P(Positive | Disease)}{P(Positive | No Disease)} = \\frac{Sensitivity}{1 - Specificity}$\n\n* **Negative Likelihood Ratio (LR-):** The ratio of the probability of a negative test result given the presence of the disease to the probability of a negative test result given the absence of the disease.\n\n$LR- = \\frac{P(Negative | Disease)}{P(Negative | No Disease)} = \\frac{1 - Sensitivity}{Specificity}$\n\n\n### Bayes' Theorem Calculation in Python\n\nLet's calculate the posterior probability using Python.  Assume:\n\n* Prior probability of disease: P(Disease) = 0.01 (1% prevalence)\n* Sensitivity = 0.95\n* Specificity = 0.90\n\n```{python}\n#| echo: true\nimport numpy as np\n\nprior_prob = 0.01\nsensitivity = 0.95\nspecificity = 0.90\n\ndef bayes_theorem(prior, sensitivity, specificity, positive_test=True):\n    if positive_test:\n        posterior = (prior * sensitivity) / ((prior * sensitivity) + ((1 - prior) * (1 - specificity)))\n    else:\n        posterior = ((1 - prior) * specificity) / (((1 - prior) * specificity) + (prior * (1 - sensitivity)))\n    return posterior\n\nposterior_positive = bayes_theorem(prior_prob, sensitivity, specificity)\nposterior_negative = bayes_theorem(prior_prob, sensitivity, specificity, positive_test=False)\n\nprint(f\"Posterior probability (positive test): {posterior_positive:.4f}\")\nprint(f\"Posterior probability (negative test): {posterior_negative:.4f}\")\n```\n\n\n### Interpreting Test Results with Python\n\nWe can visualize the impact of different prior probabilities on the posterior probability.\n\n```{python}\n#| echo: true\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nprior_probs = np.linspace(0.01, 0.2, 50) # Range of prior probabilities\nposteriors_positive = [bayes_theorem(p, sensitivity, specificity) for p in prior_probs]\nposteriors_negative = [bayes_theorem(p, sensitivity, specificity, positive_test=False) for p in prior_probs]\n\n\nplt.plot(prior_probs, posteriors_positive, label='Positive Test Result')\nplt.plot(prior_probs, posteriors_negative, label='Negative Test Result')\nplt.xlabel('Prior Probability of Disease')\nplt.ylabel('Posterior Probability of Disease')\nplt.title('Impact of Prior Probability on Posterior Probability')\nplt.legend()\nplt.show()\n```\n\nThis plot shows how the posterior probability changes with varying prior probabilities for both positive and negative test results.\n\n\n### Multiple Diagnostic Tests\n\nWhen multiple diagnostic tests are available, Bayes' theorem can be applied sequentially.  The posterior probability from one test becomes the prior probability for the next.  This allows for a more refined estimate of the disease probability.  The implementation would involve chaining the `bayes_theorem` function above, using the output of one call as the input for the next.  A detailed example with multiple tests and visualizations is beyond the scope of this concise chapter, but the principle remains the same: iteratively updating probabilities using Bayes' theorem.  A simple mermaid diagram can illustrate this concept:\n\n```{mermaid}\ngraph LR\nA[Prior Probability] --> B{Test 1};\nB -- Positive --> C[Posterior Probability (Test 1)];\nC --> D{Test 2};\nD -- Positive --> E[Posterior Probability (Test 2)];\nE --> F[Final Diagnosis];\nB -- Negative --> G[Posterior Probability (Test 1)];\nG --> D;\n\n```\nThis diagram shows how the posterior probability from one test feeds into the next test.  Note that this is a simplified example and may require adaptations depending on the nature and dependence of the tests.\n\n\n## Risk Assessment and Prediction\n\nRisk assessment is essential in healthcare for identifying individuals at high risk of developing specific diseases or experiencing adverse events. Bayes' theorem and related techniques provide powerful tools for quantifying and managing risk.\n\n### Risk Stratification\n\nRisk stratification involves categorizing individuals into different risk groups based on their probability of experiencing a particular outcome. This often involves combining multiple risk factors using statistical models.  For example, patients with cardiovascular disease might be stratified into low, medium, and high risk groups based on factors like age, blood pressure, cholesterol levels, and smoking status.  The goal is to tailor preventative measures and treatments to the individual's risk level.\n\n### Bayesian Networks for Risk Prediction\n\nBayesian networks are probabilistic graphical models that represent relationships between variables using directed acyclic graphs (DAGs).  Each node represents a variable (e.g., risk factor, disease), and the edges represent probabilistic dependencies between them.  Bayesian networks allow for efficient calculation of conditional probabilities, making them suitable for risk prediction. For instance, we can model the relationship between multiple risk factors and the probability of a heart attack.  The network can be used to update the probability of a heart attack given specific values of the risk factors.\n\nUnfortunately, constructing and visualizing complex Bayesian networks within this text is beyond scope, but the mathematical foundations remain relevant to the Bayesian updating process.\n\n\n### Modeling Risk Factors with Python\n\nWe can model the relationship between risk factors and the outcome using logistic regression, a statistical model suitable for binary outcomes (e.g., disease present/absent).\n\n```{python}\n#| echo: true\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Sample data (replace with your actual data)\ndata = {'age': [40, 50, 60, 45, 55, 65],\n        'blood_pressure': [120, 140, 160, 130, 150, 170],\n        'cholesterol': [180, 220, 260, 190, 230, 270],\n        'disease': [0, 1, 1, 0, 1, 1]}\ndf = pd.DataFrame(data)\n\nX = df[['age', 'blood_pressure', 'cholesterol']]\ny = df['disease']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Confusion Matrix:\\n{conf_matrix}\")\n```\n\nThis code demonstrates a simple logistic regression model.  In real-world applications, more complex models and feature engineering are usually necessary.\n\n\n### Predictive Modeling using Machine Learning\n\nVarious machine learning algorithms (e.g., support vector machines, random forests, neural networks) can be used for predictive modeling. These algorithms can handle complex relationships between risk factors and outcomes, potentially improving prediction accuracy.  The choice of algorithm depends on the characteristics of the data and the specific problem.  The Python code above demonstrates a simple example using Logistic Regression;  other algorithms would require different model instantiation and training.\n\n### Assessing Model Performance\n\nModel performance is assessed using metrics like accuracy, precision, recall, F1-score, and the area under the ROC curve (AUC).  The confusion matrix, shown in the previous example, provides a detailed breakdown of the model's performance.  The choice of metric depends on the relative importance of true positives, true negatives, false positives, and false negatives in the specific context.\n\n```{python}\n#| echo: true\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\n\n# ... (previous code) ...\n\nroc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\nfpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n\nplt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=4)\nplt.show()\n\n```\nThis code calculates and plots the ROC curve and AUC, providing a visual representation of the model's ability to distinguish between the two classes.\n\n\n### Uncertainty Quantification in Risk Assessment\n\nRisk predictions are inherently uncertain.  Bayesian methods provide a natural framework for quantifying this uncertainty.  Instead of providing a single point estimate of risk, Bayesian methods provide a probability distribution over possible risk levels.  This distribution reflects the uncertainty associated with the model parameters and the input data.  For instance, instead of saying \"the patient has a 60% risk of heart attack\", a Bayesian approach might give a probability distribution that shows a range of likely probabilities, reflecting the model's uncertainty.  This uncertainty can be visualized using credible intervals or probability density functions.  However, detailed quantification of uncertainty in Bayesian models often requires more advanced statistical techniques beyond the scope of this introductory section.\n\n\n## Treatment Decision Support Systems\n\nTreatment decision support systems (TDSS) aim to assist healthcare professionals in making optimal treatment choices based on patient characteristics, disease severity, and available treatment options.  Bayes' theorem plays an important role in these systems by providing a framework for updating probabilities based on new information.\n\n\n### Decision Trees and Bayes' Theorem\n\nDecision trees are a common approach in TDSS. Each node represents a decision point (e.g., test result, patient characteristic), and each branch represents a possible outcome.  Bayes' theorem can be integrated to update probabilities at each node, refining the decision-making process as more information becomes available. For example, a decision tree might start with a prior probability of a disease, then use Bayes' Theorem to update this probability based on a test result, before making a treatment recommendation.\n\n\n### Utility Theory and Expected Value\n\nUtility theory provides a framework for quantifying the value or desirability of different health outcomes.  The expected value of a treatment is calculated by weighting the utility of each possible outcome by its probability:\n\n$EV = \\sum_{i=1}^{n} U_i \\times P_i$\n\nwhere:\n* $EV$ is the expected value of the treatment\n* $U_i$ is the utility of outcome $i$\n* $P_i$ is the probability of outcome $i$\n\nTDSS can use utility theory to compare the expected values of different treatment options, helping to identify the optimal choice.\n\n\n### Cost-Effectiveness Analysis\n\nCost-effectiveness analysis (CEA) compares the costs and benefits of different treatment options.  The incremental cost-effectiveness ratio (ICER) is a common metric:\n\n$ICER = \\frac{C_A - C_B}{E_A - E_B}$\n\nwhere:\n* $C_A$ and $C_B$ are the costs of treatments A and B\n* $E_A$ and $E_B$ are the effectiveness of treatments A and B (e.g., life years gained)\n\nTDSS can integrate CEA to guide treatment choices, balancing cost and effectiveness.\n\n\n### Incorporating Patient Preferences\n\nPatient preferences play a essential role in treatment decisions.  Methods like conjoint analysis or multi-criteria decision analysis can be used to elicit and quantify patient preferences, which can then be incorporated into the TDSS.  These methods allow for personalization of treatment recommendations.\n\n\n### Developing a Treatment Decision Support System in Python\n\nLet's create a simplified example of a TDSS using Python. This example only scratches the surface; real-world TDSS are significantly more complex.\n\n```{python}\n#| echo: true\nimport numpy as np\n\n# Prior probability of disease\nprior_prob = 0.1\n\n# Likelihood ratios for test result (positive/negative)\nlr_positive = 5  \nlr_negative = 0.2\n\n# Utility of different outcomes (0 = no treatment, 1= treatment A, 2= treatment B)\nutility = np.array([[0.8, 0.7, 0.6], #no disease\n                    [0.9, 0.95, 0.85]]) #disease\n\n# Function to update probability using Bayes' theorem\ndef update_prob(prior, lr, positive_test):\n  if positive_test:\n    posterior = (prior * lr) / ((prior * lr) + (1 - prior))\n  else:\n    posterior = prior * (1 - lr) / (prior * (1 - lr) + (1 - prior))\n  return posterior\n\n# Example: Positive test result\nposterior_prob = update_prob(prior_prob, lr_positive, True)\n\n#Expected Utility Calculation (simplified - assumes only 1 test)\neu_A = utility[1,1]*posterior_prob + utility[0,1]*(1-posterior_prob)\neu_B = utility[1,2]*posterior_prob + utility[0,2]*(1-posterior_prob)\neu_none = utility[1,0]*posterior_prob + utility[0,0]*(1-posterior_prob)\n\n\nprint(f\"Posterior probability (positive test): {posterior_prob:.4f}\")\nprint(f\"Expected utility Treatment A: {eu_A:.4f}\")\nprint(f\"Expected utility Treatment B: {eu_B:.4f}\")\nprint(f\"Expected utility No Treatment: {eu_none:.4f}\")\n\n\nbest_treatment = np.argmax([eu_A, eu_B, eu_none])\nprint(f\"Recommended Treatment: {best_treatment}\")\n\n```\nThis simplified example demonstrates the core logic. A real TDSS would involve more complex models, incorporate patient preferences, and handle multiple tests and treatments.\n\n\n### Ethical Considerations in Treatment Decisions\n\nTDSS must be developed and used ethically, ensuring fairness, transparency, and accountability.  Consideration should be given to potential biases in the data and algorithms, the impact on patient autonomy, and the responsibility for decision-making.  Regular audits and validation are essential to maintain the integrity and trustworthiness of TDSS.  Further, equitable access to the system should be prioritized.\n\n\n## Case Studies in Medical Diagnosis\n\nThis section presents case studies illustrating the application of Bayes' theorem and related methods in medical diagnosis.  Due to the complexity and sensitivity of real medical data, these examples use simplified scenarios for illustrative purposes.  Real-world applications require careful consideration of ethical and privacy implications, as well as the use of robust statistical methods and validation techniques.\n\n\n### Case Study 1: Diagnosing a Specific Disease\n\nLet's consider the diagnosis of a rare disease, \"Disease X,\" with a prevalence of 0.005 (0.5%). A new diagnostic test for Disease X has been developed with the following characteristics:\n\n* Sensitivity: 0.9 (90%)\n* Specificity: 0.99 (99%)\n\nA patient undergoes the test, and the result is positive. What is the probability that the patient actually has Disease X?\n\nWe can use Bayes' theorem to calculate the positive predictive value (PPV):\n\n$PPV = P(Disease | Positive) = \\frac{Sensitivity \\times P(Disease)}{Sensitivity \\times P(Disease) + (1 - Specificity) \\times (1 - P(Disease))}$\n\n```{python}\n#| echo: true\nprior_prob = 0.005\nsensitivity = 0.9\nspecificity = 0.99\n\nppv = (sensitivity * prior_prob) / (sensitivity * prior_prob + (1 - specificity) * (1 - prior_prob))\n\nprint(f\"Positive Predictive Value (PPV): {ppv:.4f}\")\n```\n\nEven with a positive test result, the PPV is relatively low due to the low prevalence of Disease X.  This highlights the importance of considering prevalence when interpreting diagnostic test results.\n\n\n### Case Study 2: Evaluating Treatment Effectiveness\n\nSuppose a new treatment (Treatment A) is being evaluated for its effectiveness in reducing mortality in patients with a specific condition.  A clinical trial is conducted, and the following results are observed:\n\n| Treatment Group | Mortality Rate | Number of Patients |\n|---|---|---|\n| Treatment A | 10% | 100 |\n| Control Group (Standard Treatment) | 20% | 100 |\n\n\nWe can use a statistical test (like a chi-squared test or Fisher's exact test) to determine if the difference in mortality rates is statistically significant.  While Bayes' Theorem isn't directly used for hypothesis testing in this case, we can use Bayesian methods to estimate the treatment effect and quantify uncertainty around the estimate.  This would involve using Bayesian models (e.g., Bayesian logistic regression) to estimate the posterior distribution of the treatment effect, providing a more complete picture of the treatment's effectiveness than a simple p-value.  Due to the complexity of Bayesian modeling, a full example is omitted here; however, libraries such as PyMC can be used to perform such analyses.\n\n\n### Case Study 3: Risk Stratification of Patients\n\nConsider patients with a history of heart disease. Several risk factors are identified: age, blood pressure, cholesterol levels, and smoking status. We can develop a risk stratification model using logistic regression to predict the probability of a cardiac event within the next 5 years.\n\n```{python}\n#| echo: true\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\n# Sample data (replace with actual data)\ndata = {'age': [55, 60, 45, 70, 50, 65],\n        'blood_pressure': [140, 160, 120, 180, 130, 170],\n        'cholesterol': [220, 250, 190, 280, 200, 260],\n        'smoking': [1, 0, 0, 1, 1, 0], # 1=smoker, 0=non-smoker\n        'cardiac_event': [1, 1, 0, 1, 0, 1]} # 1=event, 0=no event\ndf = pd.DataFrame(data)\n\nX = df[['age', 'blood_pressure', 'cholesterol', 'smoking']]\ny = df['cardiac_event']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\nprobabilities = model.predict_proba(X_test)[:, 1]\nauc = roc_auc_score(y_test, probabilities)\n\nprint(f\"AUC: {auc:.2f}\")\nprint(f\"Predicted Probabilities: {probabilities}\")\n```\n\nThis code uses logistic regression to predict the probability of a cardiac event.  Patients can then be stratified into low, medium, and high-risk groups based on their predicted probabilities.  The AUC value assesses the model's discriminative ability.  A more robust model would likely require more data, feature engineering, and possibly more advanced machine learning techniques.  Moreover, the choice of thresholds for risk stratification needs careful consideration and depends on clinical guidelines and the cost-benefit implications of different interventions.\n\n\nNote:  These case studies provide simplified examples.  Real-world applications would involve much larger datasets, more complex models, and thorough validation procedures.  Always consult with medical professionals for proper interpretation and application of these methods in clinical settings.\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"html-math-method":{"method":"mathjax","url":"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"},"output-file":"medical-diagnosis.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","jupyter":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"bibliography":["../../references.bib"],"theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":true,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"printing","toc":true,"toc-depth":2,"include-in-header":{"text":"\\usepackage{geometry}\n\\usepackage{wrapfig}\n\\usepackage{fvextra}\n\\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n\\geometry{\n    paperwidth=6in,\n    paperheight=9in,\n    textwidth=4.5in, % Adjust this to your preferred text width\n    textheight=6.5in,  % Adjust this to your preferred text height\n    inner=0.75in,    % Adjust margins as needed\n    outer=0.75in,\n    top=0.75in,\n    bottom=1in\n}\n\\usepackage{makeidx}\n\\usepackage{tabularx}\n\\usepackage{float}\n\\usepackage{graphicx}\n\\usepackage{array}\n\\graphicspath{{diagrams/}}\n\\makeindex\n"},"include-after-body":{"text":"\\printindex\n"},"output-file":"medical-diagnosis.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"jupyter":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"bibliography":["../../references.bib"],"documentclass":"scrreprt","lof":false,"lot":false,"float":true,"classoption":"paper=6in:9in,pagesize=pdftex,footinclude=on,11pt","fig-cap-location":"top","urlcolor":"blue","linkcolor":"black","biblio-style":"apalike","code-block-bg":"#f0f0f0","code-block-border-left":"#000000","mermaid":{"theme":"neutral"},"fontfamily":"libertinus","monofont":"Consolas","monofontoptions":["Scale=0.7"],"template-partials":["../../before-body.tex"],"indent":true},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}