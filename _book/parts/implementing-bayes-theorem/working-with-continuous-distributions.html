<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>9&nbsp; Introduction to Continuous Probability Distributions – bayes-theorem-book</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../parts/implementing-bayes-theorem/discrete-probability-examples.html" rel="next">
<link href="../../parts/implementing-bayes-theorem/basic-implementation.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a2a08d6480f1a07d2e84f5b3bded3372.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../parts/implementing-bayes-theorem/intro.html">Implementing Bayes’ Theorem</a></li><li class="breadcrumb-item"><a href="../../parts/implementing-bayes-theorem/working-with-continuous-distributions.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Continuous Probability Distributions</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">bayes-theorem-book</a> 
        <div class="sidebar-tools-main">
    <a href="../../bayes-theorem-book.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/introduction-to-bayesian-thinking/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Bayesian Thinking</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/introduction-to-bayesian-thinking/understanding-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/introduction-to-bayesian-thinking/bayes-theorem-fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayes’ Theorem Fundamentals</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/introduction-to-bayesian-thinking/setting-up-python-environment.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Setting Up Python Environment</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/mathematical-foundations/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematical Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/mathematical-foundations/probability-theory-essentials.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/mathematical-foundations/statistical-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Basic Probability Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/mathematical-foundations/linear-algebra-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Linear Algebra Review</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/implementing-bayes-theorem/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Implementing Bayes' Theorem</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/implementing-bayes-theorem/basic-implementation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Basic Implementation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/implementing-bayes-theorem/working-with-continuous-distributions.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Continuous Probability Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/implementing-bayes-theorem/discrete-probability-examples.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduction to Discrete Probability</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/bayesian-inference/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayesian Inference</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/bayesian-inference/parameter-estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to Parameter Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/bayesian-inference/conjugate-priors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Conjugate Priors</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/bayesian-inference/prior-selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Prior Selection</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/markov-chain-monte-carlo-mcmc/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Markov Chain Monte Carlo (MCMC)</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/markov-chain-monte-carlo-mcmc/introduction-to-mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Monte Carlo Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/markov-chain-monte-carlo-mcmc/mcmc-algorithms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Introduction to MCMC</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/markov-chain-monte-carlo-mcmc/implementation-with-pymc3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Implementation with PyMC</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/practical-applications/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Practical Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/practical-applications/ab-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to A/B Testing</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/practical-applications/text-classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Introduction to Text Classification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/practical-applications/medical-diagnosis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Disease Testing with Bayes’ Theorem</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/advanced-topics/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/advanced-topics/hierarchical-bayesian-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Hierarchical Bayesian Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/advanced-topics/bayesian-neural-networks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Introduction to Bayesian Neural Networks</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/advanced-topics/gaussian-processes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Gaussian Processes</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/real-world-applications/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Real-World Applications</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/real-world-applications/finance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Finance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/real-world-applications/marketing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Bayesian Methods in Customer Segmentation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/real-world-applications/scientific-applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Scientific Applications</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../../parts/best-practices-and-advanced-tools/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Best Practices and Advanced Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/best-practices-and-advanced-tools/code-organization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Code Organization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/best-practices-and-advanced-tools/performance-optimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Understanding Performance Bottlenecks in Bayesian Computations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../parts/best-practices-and-advanced-tools/modern-bayesian-libraries.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Modern Bayesian Libraries</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-are-continuous-distributions" id="toc-what-are-continuous-distributions" class="nav-link active" data-scroll-target="#what-are-continuous-distributions"><span class="header-section-number">9.0.1</span> What are Continuous Distributions?</a></li>
  <li><a href="#probability-density-functions-pdfs" id="toc-probability-density-functions-pdfs" class="nav-link" data-scroll-target="#probability-density-functions-pdfs"><span class="header-section-number">9.0.2</span> Probability Density Functions (PDFs)</a></li>
  <li><a href="#cumulative-distribution-functions-cdfs" id="toc-cumulative-distribution-functions-cdfs" class="nav-link" data-scroll-target="#cumulative-distribution-functions-cdfs"><span class="header-section-number">9.0.3</span> Cumulative Distribution Functions (CDFs)</a></li>
  <li><a href="#working-with-pdfs-and-cdfs-in-python" id="toc-working-with-pdfs-and-cdfs-in-python" class="nav-link" data-scroll-target="#working-with-pdfs-and-cdfs-in-python"><span class="header-section-number">9.0.4</span> Working with PDFs and CDFs in Python</a></li>
  <li><a href="#the-normal-distribution" id="toc-the-normal-distribution" class="nav-link" data-scroll-target="#the-normal-distribution"><span class="header-section-number">9.1</span> The Normal Distribution</a>
  <ul class="collapse">
  <li><a href="#properties-of-the-normal-distribution" id="toc-properties-of-the-normal-distribution" class="nav-link" data-scroll-target="#properties-of-the-normal-distribution"><span class="header-section-number">9.1.1</span> Properties of the Normal Distribution</a></li>
  <li><a href="#standard-normal-distribution" id="toc-standard-normal-distribution" class="nav-link" data-scroll-target="#standard-normal-distribution"><span class="header-section-number">9.1.2</span> Standard Normal Distribution</a></li>
  <li><a href="#calculating-probabilities-with-the-normal-distribution" id="toc-calculating-probabilities-with-the-normal-distribution" class="nav-link" data-scroll-target="#calculating-probabilities-with-the-normal-distribution"><span class="header-section-number">9.1.3</span> Calculating Probabilities with the Normal Distribution</a></li>
  <li><a href="#python-implementation-using-scipy" id="toc-python-implementation-using-scipy" class="nav-link" data-scroll-target="#python-implementation-using-scipy"><span class="header-section-number">9.1.4</span> Python Implementation using SciPy</a></li>
  <li><a href="#visualizing-the-normal-distribution" id="toc-visualizing-the-normal-distribution" class="nav-link" data-scroll-target="#visualizing-the-normal-distribution"><span class="header-section-number">9.1.5</span> Visualizing the Normal Distribution</a></li>
  <li><a href="#applications-of-the-normal-distribution-in-bayesian-analysis" id="toc-applications-of-the-normal-distribution-in-bayesian-analysis" class="nav-link" data-scroll-target="#applications-of-the-normal-distribution-in-bayesian-analysis"><span class="header-section-number">9.1.6</span> Applications of the Normal Distribution in Bayesian Analysis</a></li>
  </ul></li>
  <li><a href="#the-beta-distribution" id="toc-the-beta-distribution" class="nav-link" data-scroll-target="#the-beta-distribution"><span class="header-section-number">9.2</span> The Beta Distribution</a>
  <ul class="collapse">
  <li><a href="#properties-of-the-beta-distribution" id="toc-properties-of-the-beta-distribution" class="nav-link" data-scroll-target="#properties-of-the-beta-distribution"><span class="header-section-number">9.2.1</span> Properties of the Beta Distribution</a></li>
  <li><a href="#beta-distribution-as-a-conjugate-prior-for-bernoulli-and-binomial" id="toc-beta-distribution-as-a-conjugate-prior-for-bernoulli-and-binomial" class="nav-link" data-scroll-target="#beta-distribution-as-a-conjugate-prior-for-bernoulli-and-binomial"><span class="header-section-number">9.2.2</span> Beta Distribution as a Conjugate Prior for Bernoulli and Binomial</a></li>
  <li><a href="#calculating-probabilities-with-the-beta-distribution" id="toc-calculating-probabilities-with-the-beta-distribution" class="nav-link" data-scroll-target="#calculating-probabilities-with-the-beta-distribution"><span class="header-section-number">9.2.3</span> Calculating Probabilities with the Beta Distribution</a></li>
  <li><a href="#python-implementation-using-scipy-1" id="toc-python-implementation-using-scipy-1" class="nav-link" data-scroll-target="#python-implementation-using-scipy-1"><span class="header-section-number">9.2.4</span> Python Implementation using SciPy</a></li>
  <li><a href="#visualizing-the-beta-distribution" id="toc-visualizing-the-beta-distribution" class="nav-link" data-scroll-target="#visualizing-the-beta-distribution"><span class="header-section-number">9.2.5</span> Visualizing the Beta Distribution</a></li>
  <li><a href="#bayesian-inference-with-beta-distribution-examples" id="toc-bayesian-inference-with-beta-distribution-examples" class="nav-link" data-scroll-target="#bayesian-inference-with-beta-distribution-examples"><span class="header-section-number">9.2.6</span> Bayesian Inference with Beta Distribution: Examples</a></li>
  </ul></li>
  <li><a href="#the-gamma-distribution" id="toc-the-gamma-distribution" class="nav-link" data-scroll-target="#the-gamma-distribution"><span class="header-section-number">9.3</span> The Gamma Distribution</a>
  <ul class="collapse">
  <li><a href="#properties-of-the-gamma-distribution" id="toc-properties-of-the-gamma-distribution" class="nav-link" data-scroll-target="#properties-of-the-gamma-distribution"><span class="header-section-number">9.3.1</span> Properties of the Gamma Distribution</a></li>
  <li><a href="#relationship-to-other-distributions-exponential-chi-squared" id="toc-relationship-to-other-distributions-exponential-chi-squared" class="nav-link" data-scroll-target="#relationship-to-other-distributions-exponential-chi-squared"><span class="header-section-number">9.3.2</span> Relationship to other distributions (Exponential, Chi-squared)</a></li>
  <li><a href="#calculating-probabilities-with-the-gamma-distribution" id="toc-calculating-probabilities-with-the-gamma-distribution" class="nav-link" data-scroll-target="#calculating-probabilities-with-the-gamma-distribution"><span class="header-section-number">9.3.3</span> Calculating Probabilities with the Gamma Distribution</a></li>
  <li><a href="#python-implementation-using-scipy-2" id="toc-python-implementation-using-scipy-2" class="nav-link" data-scroll-target="#python-implementation-using-scipy-2"><span class="header-section-number">9.3.4</span> Python Implementation using SciPy</a></li>
  <li><a href="#visualizing-the-gamma-distribution" id="toc-visualizing-the-gamma-distribution" class="nav-link" data-scroll-target="#visualizing-the-gamma-distribution"><span class="header-section-number">9.3.5</span> Visualizing the Gamma Distribution</a></li>
  <li><a href="#bayesian-inference-with-gamma-distribution-examples" id="toc-bayesian-inference-with-gamma-distribution-examples" class="nav-link" data-scroll-target="#bayesian-inference-with-gamma-distribution-examples"><span class="header-section-number">9.3.6</span> Bayesian Inference with Gamma Distribution: Examples</a></li>
  </ul></li>
  <li><a href="#bayesian-inference-with-continuous-distributions" id="toc-bayesian-inference-with-continuous-distributions" class="nav-link" data-scroll-target="#bayesian-inference-with-continuous-distributions"><span class="header-section-number">9.4</span> Bayesian Inference with Continuous Distributions</a>
  <ul class="collapse">
  <li><a href="#prior-and-posterior-distributions" id="toc-prior-and-posterior-distributions" class="nav-link" data-scroll-target="#prior-and-posterior-distributions"><span class="header-section-number">9.4.1</span> Prior and Posterior Distributions</a></li>
  <li><a href="#updating-beliefs-with-data" id="toc-updating-beliefs-with-data" class="nav-link" data-scroll-target="#updating-beliefs-with-data"><span class="header-section-number">9.4.2</span> Updating Beliefs with Data</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc-methods" id="toc-markov-chain-monte-carlo-mcmc-methods" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc-methods"><span class="header-section-number">9.4.3</span> Markov Chain Monte Carlo (MCMC) Methods</a></li>
  <li><a href="#illustrative-examples-using-pymc-or-similar-libraries" id="toc-illustrative-examples-using-pymc-or-similar-libraries" class="nav-link" data-scroll-target="#illustrative-examples-using-pymc-or-similar-libraries"><span class="header-section-number">9.4.4</span> Illustrative Examples using PyMC or similar libraries</a></li>
  </ul></li>
  <li><a href="#advanced-topics-and-applications" id="toc-advanced-topics-and-applications" class="nav-link" data-scroll-target="#advanced-topics-and-applications"><span class="header-section-number">9.5</span> Advanced Topics and Applications</a>
  <ul class="collapse">
  <li><a href="#mixture-models" id="toc-mixture-models" class="nav-link" data-scroll-target="#mixture-models"><span class="header-section-number">9.5.1</span> Mixture Models</a></li>
  <li><a href="#hierarchical-models" id="toc-hierarchical-models" class="nav-link" data-scroll-target="#hierarchical-models"><span class="header-section-number">9.5.2</span> Hierarchical Models</a></li>
  <li><a href="#dealing-with-improper-priors" id="toc-dealing-with-improper-priors" class="nav-link" data-scroll-target="#dealing-with-improper-priors"><span class="header-section-number">9.5.3</span> Dealing with Improper Priors</a></li>
  <li><a href="#model-selection-and-comparison" id="toc-model-selection-and-comparison" class="nav-link" data-scroll-target="#model-selection-and-comparison"><span class="header-section-number">9.5.4</span> Model Selection and Comparison</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../parts/implementing-bayes-theorem/intro.html">Implementing Bayes’ Theorem</a></li><li class="breadcrumb-item"><a href="../../parts/implementing-bayes-theorem/working-with-continuous-distributions.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Continuous Probability Distributions</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Continuous Probability Distributions</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="what-are-continuous-distributions" class="level3" data-number="9.0.1">
<h3 data-number="9.0.1" class="anchored" data-anchor-id="what-are-continuous-distributions"><span class="header-section-number">9.0.1</span> What are Continuous Distributions?</h3>
<p>Discrete probability distributions deal with variables that can only take on specific, separate values (e.g., the number of heads in three coin flips). Continuous probability distributions, on the other hand, describe variables that can take on any value within a given range. Examples include height, weight, temperature, and time. Because there are infinitely many values within any interval, the probability of a continuous random variable taking on any <em>single</em> specific value is technically zero. Instead, we talk about the probability of the variable falling within a <em>range</em> of values.</p>
</section>
<section id="probability-density-functions-pdfs" class="level3" data-number="9.0.2">
<h3 data-number="9.0.2" class="anchored" data-anchor-id="probability-density-functions-pdfs"><span class="header-section-number">9.0.2</span> Probability Density Functions (PDFs)</h3>
<p>For a continuous random variable <span class="math inline">\(X\)</span>, its probability density function (PDF), denoted as <span class="math inline">\(f(x)\)</span>, describes the relative likelihood of the variable taking on a given value. Crucially, <span class="math inline">\(f(x)\)</span> is <em>not</em> a probability itself. Instead, the probability that <span class="math inline">\(X\)</span> falls within an interval <span class="math inline">\([a, b]\)</span> is given by the integral of the PDF over that interval:</p>
<p><span class="math inline">\(P(a \le X \le b) = \int_a^b f(x) \, dx\)</span></p>
<p>The PDF must satisfy two conditions:</p>
<ol type="1">
<li><span class="math inline">\(f(x) \ge 0\)</span> for all <span class="math inline">\(x\)</span>.</li>
<li><span class="math inline">\(\int_{-\infty}^{\infty} f(x) \, dx = 1\)</span> (The total area under the curve must equal 1).</li>
</ol>
</section>
<section id="cumulative-distribution-functions-cdfs" class="level3" data-number="9.0.3">
<h3 data-number="9.0.3" class="anchored" data-anchor-id="cumulative-distribution-functions-cdfs"><span class="header-section-number">9.0.3</span> Cumulative Distribution Functions (CDFs)</h3>
<p>The cumulative distribution function (CDF), denoted as <span class="math inline">\(F(x)\)</span>, gives the probability that the random variable <span class="math inline">\(X\)</span> is less than or equal to a given value <span class="math inline">\(x\)</span>:</p>
<p><span class="math inline">\(F(x) = P(X \le x) = \int_{-\infty}^x f(t) \, dt\)</span></p>
<p>The CDF is a non-decreasing function, meaning <span class="math inline">\(F(x_1) \le F(x_2)\)</span> if <span class="math inline">\(x_1 \le x_2\)</span>. It’s also true that <span class="math inline">\(P(a &lt; X \le b) = F(b) - F(a)\)</span>. The CDF provides a convenient way to calculate probabilities for various intervals.</p>
</section>
<section id="working-with-pdfs-and-cdfs-in-python" class="level3" data-number="9.0.4">
<h3 data-number="9.0.4" class="anchored" data-anchor-id="working-with-pdfs-and-cdfs-in-python"><span class="header-section-number">9.0.4</span> Working with PDFs and CDFs in Python</h3>
<p>Python libraries like SciPy provide tools for working with continuous distributions. Let’s illustrate using the normal distribution as an example:</p>
<div id="03fffc75" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define parameters for the normal distribution</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> <span class="dv">0</span>  <span class="co"># Mean</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="dv">1</span> <span class="co"># Standard deviation</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a normal distribution object</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>norm_dist <span class="op">=</span> stats.norm(loc<span class="op">=</span>mu, scale<span class="op">=</span>sigma)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate x values for plotting</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">100</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PDF values</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> norm_dist.pdf(x)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate CDF values</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> norm_dist.cdf(x)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the PDF</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf_values)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Probability Density Function (PDF) of Normal Distribution'</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'f(x)'</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting the CDF</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>plt.plot(x, cdf_values)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Cumulative Distribution Function (CDF) of Normal Distribution'</span>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'x'</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'F(x)'</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probability between -1 and 1</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>probability <span class="op">=</span> norm_dist.cdf(<span class="dv">1</span>) <span class="op">-</span> norm_dist.cdf(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability between -1 and 1: </span><span class="sc">{</span>probability<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co">#Example using ppf (percent point function) - inverse of CDF</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>percentile_95 <span class="op">=</span> norm_dist.ppf(<span class="fl">0.95</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"95th percentile: </span><span class="sc">{</span>percentile_95<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-2-output-1.png" width="821" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-2-output-2.png" width="812" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Probability between -1 and 1: 0.6826894921370859
95th percentile: 1.6448536269514722</code></pre>
</div>
</div>
<p>This code demonstrates how to:</p>
<ol type="1">
<li>Create a normal distribution object using SciPy.</li>
<li>Calculate PDF and CDF values at various points.</li>
<li>Plot the PDF and CDF using Matplotlib.</li>
<li>Calculate probabilities using the CDF.</li>
<li>Use the percent point function (ppf), the inverse of the CDF.</li>
</ol>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Normal Distribution] --&gt; B(PDF);
    A --&gt; C(CDF);
    B --&gt; D{Calculate Probabilities};
    C --&gt; D;
    D --&gt; E[Interpret Results];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram shows the relationship between the normal distribution, its PDF and CDF, and how they are used to calculate and interpret probabilities.</p>
</section>
<section id="the-normal-distribution" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="the-normal-distribution"><span class="header-section-number">9.1</span> The Normal Distribution</h2>
<section id="properties-of-the-normal-distribution" class="level3" data-number="9.1.1">
<h3 data-number="9.1.1" class="anchored" data-anchor-id="properties-of-the-normal-distribution"><span class="header-section-number">9.1.1</span> Properties of the Normal Distribution</h3>
<p>The normal distribution, also known as the Gaussian distribution, is arguably the most important continuous probability distribution. Its probability density function (PDF) is given by:</p>
<p><span class="math inline">\(f(x; \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> is the mean (average) of the distribution, representing the center of the distribution.</li>
<li><span class="math inline">\(\sigma\)</span> is the standard deviation, representing the spread or dispersion of the distribution. A larger <span class="math inline">\(\sigma\)</span> indicates greater spread.</li>
<li><span class="math inline">\(\sigma^2\)</span> is the variance.</li>
</ul>
<p>Key properties:</p>
<ul>
<li><strong>Symmetrical:</strong> The distribution is perfectly symmetrical around its mean.</li>
<li><strong>Unimodal:</strong> It has a single peak at the mean.</li>
<li><strong>Bell-shaped:</strong> Its characteristic bell shape is easily recognizable.</li>
<li><strong>Empirical Rule:</strong> Approximately 68% of the data falls within one standard deviation of the mean (<span class="math inline">\(\mu \pm \sigma\)</span>), 95% within two standard deviations (<span class="math inline">\(\mu \pm 2\sigma\)</span>), and 99.7% within three standard deviations (<span class="math inline">\(\mu \pm 3\sigma\)</span>).</li>
</ul>
</section>
<section id="standard-normal-distribution" class="level3" data-number="9.1.2">
<h3 data-number="9.1.2" class="anchored" data-anchor-id="standard-normal-distribution"><span class="header-section-number">9.1.2</span> Standard Normal Distribution</h3>
<p>The standard normal distribution is a special case of the normal distribution where <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\sigma = 1\)</span>. It’s denoted as <span class="math inline">\(N(0, 1)\)</span>. Any normally distributed variable <span class="math inline">\(X\)</span> can be standardized by transforming it into a standard normal variable <span class="math inline">\(Z\)</span> using the following formula:</p>
<p><span class="math inline">\(Z = \frac{X - \mu}{\sigma}\)</span></p>
<p>This transformation allows us to use standard normal tables or software to calculate probabilities for any normal distribution.</p>
</section>
<section id="calculating-probabilities-with-the-normal-distribution" class="level3" data-number="9.1.3">
<h3 data-number="9.1.3" class="anchored" data-anchor-id="calculating-probabilities-with-the-normal-distribution"><span class="header-section-number">9.1.3</span> Calculating Probabilities with the Normal Distribution</h3>
<p>To calculate probabilities using the normal distribution, we typically use the CDF, <span class="math inline">\(F(x)\)</span>, which gives <span class="math inline">\(P(X \le x)\)</span>. For the standard normal distribution, we often denote the CDF as <span class="math inline">\(\Phi(z)\)</span>. We can find these probabilities using statistical tables or software. For example:</p>
<p><span class="math inline">\(P(a \le X \le b) = F(b) - F(a) = \Phi(\frac{b - \mu}{\sigma}) - \Phi(\frac{a - \mu}{\sigma})\)</span></p>
</section>
<section id="python-implementation-using-scipy" class="level3" data-number="9.1.4">
<h3 data-number="9.1.4" class="anchored" data-anchor-id="python-implementation-using-scipy"><span class="header-section-number">9.1.4</span> Python Implementation using SciPy</h3>
<p>SciPy’s <code>scipy.stats</code> module provides convenient functions for working with the normal distribution:</p>
<div id="4f6fc21d" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters for a normal distribution</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>mu <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a normal distribution object</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>norm_dist <span class="op">=</span> stats.norm(loc<span class="op">=</span>mu, scale<span class="op">=</span>sigma)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability density function (PDF)</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(mu <span class="op">-</span> <span class="dv">4</span><span class="op">*</span>sigma, mu <span class="op">+</span> <span class="dv">4</span><span class="op">*</span>sigma, <span class="dv">100</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> norm_dist.pdf(x)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Cumulative distribution function (CDF)</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> norm_dist.cdf(x)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability between two values</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>prob_interval <span class="op">=</span> norm_dist.cdf(<span class="dv">7</span>) <span class="op">-</span> norm_dist.cdf(<span class="dv">3</span>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting the PDF</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf_values)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Normal Distribution PDF"</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"f(x)"</span>)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting the CDF</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>plt.plot(x, cdf_values)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Normal Distribution CDF"</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"F(x)"</span>)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability between 3 and 7: </span><span class="sc">{</span>prob_interval<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-3-output-1.png" width="829" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-3-output-2.png" width="812" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Probability between 3 and 7: 0.6826894921370859</code></pre>
</div>
</div>
</section>
<section id="visualizing-the-normal-distribution" class="level3" data-number="9.1.5">
<h3 data-number="9.1.5" class="anchored" data-anchor-id="visualizing-the-normal-distribution"><span class="header-section-number">9.1.5</span> Visualizing the Normal Distribution</h3>
<p>The code above includes plotting the PDF and CDF. This visualization helps understand the distribution’s shape and probabilities.</p>
</section>
<section id="applications-of-the-normal-distribution-in-bayesian-analysis" class="level3" data-number="9.1.6">
<h3 data-number="9.1.6" class="anchored" data-anchor-id="applications-of-the-normal-distribution-in-bayesian-analysis"><span class="header-section-number">9.1.6</span> Applications of the Normal Distribution in Bayesian Analysis</h3>
<p>The normal distribution plays a essential role in Bayesian analysis, particularly as a prior distribution (representing our initial beliefs about a parameter) or as a likelihood function (representing the probability of observing data given a parameter value). For example, in Bayesian linear regression, the prior for the regression coefficients is often assumed to be normally distributed. Conjugate priors (priors that lead to posterior distributions of the same family) are frequently used for computational convenience and the normal distribution paired with a normal likelihood results in a normal posterior. This simplifies calculations and interpretation. The Central Limit Theorem further reinforces the importance of the normal distribution; the sum of many independent random variables, irrespective of their individual distributions, tends towards a normal distribution. This means many real-world phenomena can be well-approximated by a normal distribution.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Prior Distribution (Normal)] --&gt; B{Bayes' Theorem};
    C[Likelihood Function (Normal)] --&gt; B;
    B --&gt; D[Posterior Distribution (Normal)];
    D --&gt; E[Inference and Predictions];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram illustrates the role of the normal distribution as a prior and likelihood in Bayesian analysis, resulting in a normal posterior distribution.</p>
</section>
</section>
<section id="the-beta-distribution" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="the-beta-distribution"><span class="header-section-number">9.2</span> The Beta Distribution</h2>
<section id="properties-of-the-beta-distribution" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="properties-of-the-beta-distribution"><span class="header-section-number">9.2.1</span> Properties of the Beta Distribution</h3>
<p>The beta distribution is a continuous probability distribution defined on the interval [0, 1]. It’s particularly useful for modeling probabilities and proportions. Its probability density function (PDF) is given by:</p>
<p><span class="math inline">\(f(x; \alpha, \beta) = \frac{x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha, \beta)}\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x \in [0, 1]\)</span></li>
<li><span class="math inline">\(\alpha &gt; 0\)</span> is a shape parameter.</li>
<li><span class="math inline">\(\beta &gt; 0\)</span> is a shape parameter.</li>
<li><span class="math inline">\(B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}\)</span> is the beta function, a normalization constant ensuring the integral of the PDF over [0,1] equals 1. <span class="math inline">\(\Gamma(.)\)</span> is the gamma function, a generalization of the factorial function to real numbers.</li>
</ul>
<p>The mean and variance of the beta distribution are:</p>
<ul>
<li>Mean: <span class="math inline">\(E[X] = \frac{\alpha}{\alpha + \beta}\)</span></li>
<li>Variance: <span class="math inline">\(Var(X) = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}\)</span></li>
</ul>
<p>The shape of the beta distribution is highly flexible depending on the values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
</section>
<section id="beta-distribution-as-a-conjugate-prior-for-bernoulli-and-binomial" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="beta-distribution-as-a-conjugate-prior-for-bernoulli-and-binomial"><span class="header-section-number">9.2.2</span> Beta Distribution as a Conjugate Prior for Bernoulli and Binomial</h3>
<p>The beta distribution is a conjugate prior for the Bernoulli and binomial distributions. This means that if the prior distribution for a parameter (e.g., the probability of success in a Bernoulli trial) is beta, then the posterior distribution after observing data from a Bernoulli or binomial experiment will also be beta. This makes Bayesian inference with these distributions particularly convenient.</p>
<p>If we have a Bernoulli likelihood with parameter <span class="math inline">\(\theta\)</span> (probability of success) and a Beta(<span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>) prior, the posterior distribution is Beta(<span class="math inline">\(\alpha + k\)</span>, <span class="math inline">\(\beta + n - k\)</span>), where <span class="math inline">\(k\)</span> is the number of successes observed in <span class="math inline">\(n\)</span> trials. Similarly, for a binomial likelihood, the posterior is also a Beta distribution.</p>
</section>
<section id="calculating-probabilities-with-the-beta-distribution" class="level3" data-number="9.2.3">
<h3 data-number="9.2.3" class="anchored" data-anchor-id="calculating-probabilities-with-the-beta-distribution"><span class="header-section-number">9.2.3</span> Calculating Probabilities with the Beta Distribution</h3>
<p>Probabilities are calculated using the CDF, which is not analytically solvable but is readily available through computational tools. SciPy provides these functions. For example, to find the probability that <span class="math inline">\(X \le x\)</span>, we use the CDF:</p>
<p><span class="math inline">\(P(X \le x) = F(x; \alpha, \beta) = \int_0^x f(t; \alpha, \beta) \, dt\)</span></p>
</section>
<section id="python-implementation-using-scipy-1" class="level3" data-number="9.2.4">
<h3 data-number="9.2.4" class="anchored" data-anchor-id="python-implementation-using-scipy-1"><span class="header-section-number">9.2.4</span> Python Implementation using SciPy</h3>
<div id="823946b6" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters for a Beta distribution</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a beta distribution object</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>beta_dist <span class="op">=</span> stats.beta(a<span class="op">=</span>alpha, b<span class="op">=</span>beta)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># PDF values</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">100</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> beta_dist.pdf(x)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># CDF values</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> beta_dist.cdf(x)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Probability between two values</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>prob_interval <span class="op">=</span> beta_dist.cdf(<span class="fl">0.6</span>) <span class="op">-</span> beta_dist.cdf(<span class="fl">0.3</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting PDF</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf_values)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Beta Distribution PDF"</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"f(x)"</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting CDF</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>plt.plot(x, cdf_values)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Beta Distribution CDF"</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"F(x)"</span>)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability between 0.3 and 0.6: </span><span class="sc">{</span>prob_interval<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-4-output-1.png" width="812" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-4-output-2.png" width="812" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Probability between 0.3 and 0.6: 0.37921499999999975</code></pre>
</div>
</div>
</section>
<section id="visualizing-the-beta-distribution" class="level3" data-number="9.2.5">
<h3 data-number="9.2.5" class="anchored" data-anchor-id="visualizing-the-beta-distribution"><span class="header-section-number">9.2.5</span> Visualizing the Beta Distribution</h3>
<p>The code above generates plots of the PDF and CDF, visually representing the distribution. Varying <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> will drastically alter the shape.</p>
</section>
<section id="bayesian-inference-with-beta-distribution-examples" class="level3" data-number="9.2.6">
<h3 data-number="9.2.6" class="anchored" data-anchor-id="bayesian-inference-with-beta-distribution-examples"><span class="header-section-number">9.2.6</span> Bayesian Inference with Beta Distribution: Examples</h3>
<p><strong>Example: Estimating the probability of heads in a biased coin.</strong></p>
<p>Suppose we flip a coin 10 times and observe 3 heads. We can use a beta prior to represent our prior belief about the probability of heads (let’s use a Beta(1,1) - a uniform prior). After observing the data, the posterior distribution will be Beta(1+3, 1+10-3) = Beta(4,8).</p>
<div id="838425c6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#Prior</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> stats.beta(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">100</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x,prior.pdf(x),label<span class="op">=</span><span class="st">'Prior'</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Posterior</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> stats.beta(<span class="dv">4</span>,<span class="dv">8</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>plt.plot(x,posterior.pdf(x),label<span class="op">=</span><span class="st">'Posterior'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"θ (Probability of heads)"</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-5-output-1.png" width="589" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This shows how the data updates our belief about the coin’s fairness.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Prior: Beta(1,1)] --&gt; B{10 flips, 3 Heads};
    B --&gt; C[Posterior: Beta(4,8)];
    C --&gt; D[Inference about θ];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram summarizes the Bayesian updating process using the beta distribution. Further examples can incorporate more complex scenarios with different priors and data.</p>
</section>
</section>
<section id="the-gamma-distribution" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="the-gamma-distribution"><span class="header-section-number">9.3</span> The Gamma Distribution</h2>
<section id="properties-of-the-gamma-distribution" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="properties-of-the-gamma-distribution"><span class="header-section-number">9.3.1</span> Properties of the Gamma Distribution</h3>
<p>The gamma distribution is a flexible two-parameter family of continuous probability distributions. It’s often used to model positive, continuous random variables, such as waiting times or durations. Its probability density function (PDF) is defined as:</p>
<p><span class="math inline">\(f(x; k, θ) = \frac{1}{Γ(k)θ^k} x^{k-1}e^{-x/θ}\)</span> for <span class="math inline">\(x ≥ 0\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(x\)</span> is the random variable.</li>
<li><span class="math inline">\(k &gt; 0\)</span> is the shape parameter, influencing the distribution’s shape.</li>
<li><span class="math inline">\(θ &gt; 0\)</span> is the scale parameter, influencing the distribution’s spread.</li>
<li><span class="math inline">\(Γ(k)\)</span> is the gamma function, a generalization of the factorial function to real numbers.</li>
</ul>
<p>The mean and variance are:</p>
<ul>
<li>Mean: <span class="math inline">\(E[X] = kθ\)</span></li>
<li>Variance: <span class="math inline">\(Var(X) = kθ^2\)</span></li>
</ul>
<p>Different combinations of <span class="math inline">\(k\)</span> and <span class="math inline">\(θ\)</span> lead to various shapes. For example, if <span class="math inline">\(k=1\)</span>, it simplifies to an exponential distribution.</p>
</section>
<section id="relationship-to-other-distributions-exponential-chi-squared" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="relationship-to-other-distributions-exponential-chi-squared"><span class="header-section-number">9.3.2</span> Relationship to other distributions (Exponential, Chi-squared)</h3>
<p>The gamma distribution has strong relationships with other important distributions:</p>
<ul>
<li><p><strong>Exponential Distribution:</strong> The exponential distribution is a special case of the gamma distribution where <span class="math inline">\(k = 1\)</span>. The exponential distribution is commonly used to model the time until an event occurs in a Poisson process (e.g., time until a machine fails).</p></li>
<li><p><strong>Chi-squared Distribution:</strong> A chi-squared distribution with <span class="math inline">\(ν\)</span> degrees of freedom is equivalent to a gamma distribution with shape parameter <span class="math inline">\(k = ν/2\)</span> and scale parameter <span class="math inline">\(θ = 2\)</span>. Chi-squared distributions are essential in hypothesis testing and statistical inference.</p></li>
</ul>
</section>
<section id="calculating-probabilities-with-the-gamma-distribution" class="level3" data-number="9.3.3">
<h3 data-number="9.3.3" class="anchored" data-anchor-id="calculating-probabilities-with-the-gamma-distribution"><span class="header-section-number">9.3.3</span> Calculating Probabilities with the Gamma Distribution</h3>
<p>Probabilities are calculated using the CDF, <span class="math inline">\(P(X ≤ x) = F(x; k, θ) = \int_0^x f(t; k, θ) \, dt\)</span>. This integral doesn’t have a closed-form solution, but it’s readily available numerically.</p>
</section>
<section id="python-implementation-using-scipy-2" class="level3" data-number="9.3.4">
<h3 data-number="9.3.4" class="anchored" data-anchor-id="python-implementation-using-scipy-2"><span class="header-section-number">9.3.4</span> Python Implementation using SciPy</h3>
<div id="e429e7f8" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters for a Gamma distribution</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Shape parameter</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>theta <span class="op">=</span> <span class="dv">3</span> <span class="co"># Scale parameter</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a gamma distribution object</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>gamma_dist <span class="op">=</span> stats.gamma(a<span class="op">=</span>k, scale<span class="op">=</span>theta)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate x values for plotting</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dv">100</span>) <span class="co">#Adjust range as needed</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate PDF values</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>pdf_values <span class="op">=</span> gamma_dist.pdf(x)</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate CDF values</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>cdf_values <span class="op">=</span> gamma_dist.cdf(x)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate probability between two values</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>prob_interval <span class="op">=</span> gamma_dist.cdf(<span class="dv">10</span>) <span class="op">-</span> gamma_dist.cdf(<span class="dv">5</span>)</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting PDF</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pdf_values)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Gamma Distribution PDF"</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"f(x)"</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="co">#Plotting CDF</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">5</span>))</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>plt.plot(x, cdf_values)</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Gamma Distribution CDF"</span>)</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"F(x)"</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability between 5 and 10: </span><span class="sc">{</span>prob_interval<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-6-output-1.png" width="820" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-6-output-2.png" width="812" height="449" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Probability between 5 and 10: 0.34908096972873787</code></pre>
</div>
</div>
</section>
<section id="visualizing-the-gamma-distribution" class="level3" data-number="9.3.5">
<h3 data-number="9.3.5" class="anchored" data-anchor-id="visualizing-the-gamma-distribution"><span class="header-section-number">9.3.5</span> Visualizing the Gamma Distribution</h3>
<p>The code above generates plots of the PDF and CDF, providing a visual representation of the distribution’s shape. The shape changes dramatically as you adjust k and theta.</p>
</section>
<section id="bayesian-inference-with-gamma-distribution-examples" class="level3" data-number="9.3.6">
<h3 data-number="9.3.6" class="anchored" data-anchor-id="bayesian-inference-with-gamma-distribution-examples"><span class="header-section-number">9.3.6</span> Bayesian Inference with Gamma Distribution: Examples</h3>
<p>The gamma distribution serves as a conjugate prior for many likelihood functions involving positive parameters, such as the Poisson distribution (for modeling counts) and the exponential distribution (for modeling waiting times). For instance, if our likelihood function is a Poisson distribution and we use a Gamma prior for the rate parameter (λ), the posterior distribution will also be a gamma distribution. This simplifies Bayesian calculations significantly.</p>
<p><strong>Example: Estimating the rate parameter of a Poisson process.</strong></p>
<p>Let’s say we are modeling the number of customers arriving at a store per hour, following a Poisson distribution. We can use a Gamma prior for the rate parameter (λ). Suppose we observe 15 customers in 5 hours (an average of 3 customers per hour). Assume our prior is Gamma(2,1). The posterior is then Gamma(2+15, 1/(1/1 + 5)).</p>
<div id="9a87aeb1" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy.stats <span class="im">as</span> stats</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> stats.gamma(a<span class="op">=</span><span class="dv">2</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">10</span>,<span class="dv">100</span>) <span class="co">#Adjust range as needed</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>plt.plot(x,prior.pdf(x), label<span class="op">=</span><span class="st">'Prior'</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior (assuming a Poisson likelihood and 15 customers in 5 hours)</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>posterior <span class="op">=</span> stats.gamma(a<span class="op">=</span><span class="dv">17</span>, scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span><span class="dv">6</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>plt.plot(x,posterior.pdf(x), label<span class="op">=</span><span class="st">'Posterior'</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"λ (Rate parameter)"</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-7-output-1.png" width="589" height="429" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This demonstrates how the observed data shifts our belief about the rate parameter.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Prior: Gamma(2,1)] --&gt; B{15 customers in 5 hours (Poisson)};
    B --&gt; C[Posterior: Gamma(17, 1/6)];
    C --&gt; D[Inference about λ];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram shows the Bayesian updating process using the gamma distribution as a conjugate prior for a Poisson likelihood. The specific parameters in the posterior would change based on your observed data and prior assumptions.</p>
</section>
</section>
<section id="bayesian-inference-with-continuous-distributions" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="bayesian-inference-with-continuous-distributions"><span class="header-section-number">9.4</span> Bayesian Inference with Continuous Distributions</h2>
<section id="prior-and-posterior-distributions" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="prior-and-posterior-distributions"><span class="header-section-number">9.4.1</span> Prior and Posterior Distributions</h3>
<p>In Bayesian inference, we start with a <em>prior distribution</em>, <span class="math inline">\(P(\theta)\)</span>, which represents our initial beliefs about the unknown parameter(s) <span class="math inline">\(\theta\)</span>. This prior can be informed by previous knowledge or expert opinion, or it can be a non-informative prior expressing minimal prior assumptions. After observing data, <span class="math inline">\(D\)</span>, we update our beliefs using Bayes’ theorem:</p>
<p><span class="math inline">\(P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}\)</span></p>
<p>The resulting <em>posterior distribution</em>, <span class="math inline">\(P(\theta|D)\)</span>, represents our updated beliefs about <span class="math inline">\(\theta\)</span> after considering the data. <span class="math inline">\(P(D|\theta)\)</span> is the likelihood function, describing the probability of observing the data given a specific value of <span class="math inline">\(\theta\)</span>, and <span class="math inline">\(P(D)\)</span> is the marginal likelihood (evidence), a normalizing constant.</p>
</section>
<section id="updating-beliefs-with-data" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="updating-beliefs-with-data"><span class="header-section-number">9.4.2</span> Updating Beliefs with Data</h3>
<p>The process of Bayesian inference involves updating our beliefs iteratively as more data becomes available. The posterior distribution from one stage becomes the prior for the next stage. This sequential updating is a fundamental aspect of Bayesian thinking. As more data is incorporated, the influence of the prior diminishes, and the posterior distribution becomes increasingly driven by the data. This is often visualized as the posterior becoming more concentrated around the true parameter value.</p>
</section>
<section id="markov-chain-monte-carlo-mcmc-methods" class="level3" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc-methods"><span class="header-section-number">9.4.3</span> Markov Chain Monte Carlo (MCMC) Methods</h3>
<p>For many complex models, calculating the posterior distribution analytically is intractable. Markov Chain Monte Carlo (MCMC) methods provide a powerful computational approach to approximate the posterior distribution. These methods simulate a Markov chain whose stationary distribution is the target posterior distribution. By running the chain for a sufficiently long time, we can obtain samples from the approximate posterior. These samples can then be used to estimate parameters, calculate credible intervals, and make predictions. Popular MCMC algorithms include:</p>
<ul>
<li><p><strong>Metropolis-Hastings:</strong> A widely used algorithm that proposes new samples and accepts or rejects them based on a probability that depends on the likelihood and prior.</p></li>
<li><p><strong>Gibbs Sampling:</strong> A special case of Metropolis-Hastings that is particularly efficient when the full conditional distributions (the distribution of one parameter given the others) are easy to sample from.</p></li>
<li><p><strong>Hamiltonian Monte Carlo (HMC):</strong> A more advanced algorithm that uses Hamiltonian dynamics to look at the parameter space more efficiently.</p></li>
</ul>
</section>
<section id="illustrative-examples-using-pymc-or-similar-libraries" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4" class="anchored" data-anchor-id="illustrative-examples-using-pymc-or-similar-libraries"><span class="header-section-number">9.4.4</span> Illustrative Examples using PyMC or similar libraries</h3>
<p>PyMC is a powerful Python library for probabilistic programming, making it easy to implement Bayesian inference using MCMC methods. Let’s consider a simple example of Bayesian linear regression:</p>
<div id="1fab1a40" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some sample data</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, N)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>true_slope <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>true_intercept <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>true_sigma <span class="op">=</span> <span class="fl">1.5</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> true_slope <span class="op">*</span> X <span class="op">+</span> true_intercept <span class="op">+</span> np.random.normal(<span class="dv">0</span>, true_sigma, N)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    slope <span class="op">=</span> pm.Normal(<span class="st">"slope"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    intercept <span class="op">=</span> pm.Normal(<span class="st">"intercept"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    sigma <span class="op">=</span> pm.HalfNormal(<span class="st">"sigma"</span>, sigma<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Likelihood</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> slope <span class="op">*</span> X <span class="op">+</span> intercept</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    y_obs <span class="op">=</span> pm.Normal(<span class="st">"y_obs"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>y)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Posterior Sampling</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    trace <span class="op">=</span> pm.sample(<span class="dv">2000</span>, tune<span class="op">=</span><span class="dv">1000</span>, cores<span class="op">=</span><span class="dv">1</span>) <span class="co"># Adjust number of samples and cores as needed</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>pm.summary(trace)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>pm.plot_posterior(trace)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Initializing NUTS using jitter+adapt_diag...
Sequential sampling (2 chains in 1 job)
NUTS: [slope, intercept, sigma]</code></pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">/home/leopard/development/QuantumTraderX/venv/lib/python3.12/site-packages/rich/live.py:231: UserWarning: install 
"ipywidgets" for Jupyter support
  warnings.warn('install "ipywidgets" for Jupyter support')
</pre>
</div>
<div class="cell-output cell-output-display">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 3 seconds.
We recommend running at least 4 chains for robust computation of convergence diagnostics</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="working-with-continuous-distributions_files/figure-html/cell-8-output-5.png" width="1816" height="496" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This code defines a Bayesian linear regression model with normal priors for the slope and intercept, and a half-normal prior for the error standard deviation. PyMC then automatically samples from the posterior distribution using an MCMC algorithm (by default, it uses the No-U-Turn Sampler, NUTS, a variant of HMC).</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Prior Distributions] --&gt; B(Likelihood Function);
    B --&gt; C[Posterior Distribution (via MCMC)];
    C --&gt; D[Inference &amp; Predictions];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram summarizes the Bayesian workflow in PyMC. The MCMC algorithms handle the challenging task of sampling from the posterior distribution. Remember to install PyMC using <code>pip install pymc3</code>. This example demonstrates how to set up a Bayesian model, define priors and likelihoods, and then use PyMC to obtain posterior samples, allowing for parameter estimation and uncertainty quantification. The summary and plot_posterior functions help you interpret the results. The quality of the MCMC sampling (convergence, etc.) is crucial, and diagnostics should be used to evaluate the quality of the chain.</p>
</section>
</section>
<section id="advanced-topics-and-applications" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="advanced-topics-and-applications"><span class="header-section-number">9.5</span> Advanced Topics and Applications</h2>
<section id="mixture-models" class="level3" data-number="9.5.1">
<h3 data-number="9.5.1" class="anchored" data-anchor-id="mixture-models"><span class="header-section-number">9.5.1</span> Mixture Models</h3>
<p>Mixture models are powerful tools for modeling data generated from multiple underlying distributions. They assume that the observed data is a mixture of samples from different component distributions, each with its own parameters. A common example is a Gaussian mixture model (GMM), where the data is assumed to be a mixture of Gaussian distributions. The probability density function of a GMM with <span class="math inline">\(K\)</span> components is:</p>
<p><span class="math inline">\(p(x|\theta) = \sum_{k=1}^K \pi_k N(x|\mu_k, \Sigma_k)\)</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(\pi_k\)</span> are the mixing proportions (probabilities of belonging to each component), with <span class="math inline">\(\sum_{k=1}^K \pi_k = 1\)</span>.</li>
<li><span class="math inline">\(N(x|\mu_k, \Sigma_k)\)</span> is the probability density function of a Gaussian distribution with mean <span class="math inline">\(\mu_k\)</span> and covariance matrix <span class="math inline">\(\Sigma_k\)</span>.</li>
</ul>
<p>Bayesian inference for mixture models involves placing prior distributions on the mixing proportions and the parameters of each component distribution. MCMC methods are typically employed to sample from the posterior distribution.</p>
</section>
<section id="hierarchical-models" class="level3" data-number="9.5.2">
<h3 data-number="9.5.2" class="anchored" data-anchor-id="hierarchical-models"><span class="header-section-number">9.5.2</span> Hierarchical Models</h3>
<p>Hierarchical models are used when data is grouped or clustered, and we assume that the parameters of the underlying distributions are related across groups. This allows for borrowing strength across groups, improving the estimation of parameters for groups with limited data. A hierarchical model can be represented as:</p>
<ul>
<li>Parameters at the group level: <span class="math inline">\(\theta_i \sim P(\theta_i|\alpha)\)</span> where <span class="math inline">\(\alpha\)</span> is a hyperparameter, shared across all groups.</li>
<li>Data within each group: <span class="math inline">\(x_{ij} \sim P(x_{ij}|\theta_i)\)</span></li>
</ul>
<p>Bayesian inference for hierarchical models involves placing prior distributions on the hyperparameters and the group-level parameters. MCMC methods are often used to sample from the posterior distribution.</p>
</section>
<section id="dealing-with-improper-priors" class="level3" data-number="9.5.3">
<h3 data-number="9.5.3" class="anchored" data-anchor-id="dealing-with-improper-priors"><span class="header-section-number">9.5.3</span> Dealing with Improper Priors</h3>
<p>An improper prior is a prior distribution that doesn’t integrate to 1 (i.e., it doesn’t have a proper probability density function). While improper priors are sometimes used to express a lack of prior knowledge, they can lead to improper posterior distributions if not used carefully. It’s essential to ensure that the posterior distribution is proper (integrable) when using improper priors. This often requires careful consideration of the likelihood function and the choice of improper prior. Often, using a weakly informative prior instead can sidestep these issues.</p>
</section>
<section id="model-selection-and-comparison" class="level3" data-number="9.5.4">
<h3 data-number="9.5.4" class="anchored" data-anchor-id="model-selection-and-comparison"><span class="header-section-number">9.5.4</span> Model Selection and Comparison</h3>
<p>Choosing the best model for a given dataset is a essential aspect of Bayesian inference. Several methods are used for model comparison:</p>
<ul>
<li><p><strong>Bayes Factor:</strong> The ratio of the marginal likelihoods of two competing models. A Bayes factor greater than 1 favors the first model.</p></li>
<li><p><strong>Deviance Information Criterion (DIC):</strong> A model selection criterion that balances model fit and complexity. Lower DIC values indicate better models.</p></li>
<li><p><strong>Leave-One-Out Cross-Validation (LOO-CV):</strong> A robust model comparison technique that estimates the out-of-sample predictive performance. Models with higher LOO-CV scores perform better on unseen data.</p></li>
</ul>
<p>PyMC provides tools for calculating some of these metrics. Model selection often involves careful consideration of the tradeoff between model fit and complexity (Occam’s Razor).</p>
<div id="e9a5bcb2" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Illustrative example (Conceptual - actual implementation requires more complex code)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Imagine we have two models, ModelA and ModelB, for the same dataset</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (Code to define and fit ModelA and ModelB using PyMC) ...</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#Model Comparison using Bayes Factor (conceptually)</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal_likelihood_A = pm.marginal_likelihood(trace_A) #Placeholder</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># marginal_likelihood_B = pm.marginal_likelihood(trace_B) #Placeholder</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># bayes_factor = marginal_likelihood_A / marginal_likelihood_B</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">#print(f"Bayes Factor (ModelA vs ModelB): {bayes_factor}")</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ... (Code to calculate DIC or LOO-CV using PyMC or other suitable libraries) ...</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is a conceptual outline. Implementing model selection rigorously requires careful consideration of the specific models and the use of appropriate functions from PyMC or other Bayesian modeling packages. Note that calculating marginal likelihoods is often computationally demanding. The code snippets are placeholders to illustrate the general approach. A complete implementation would be significantly more extensive, especially for more complex models.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">graph LR
    A[Model A] --&gt; B(Bayes Factor/DIC/LOO-CV);
    C[Model B] --&gt; B;
    B --&gt; D[Model Selection];
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>This diagram illustrates the process of model selection using Bayes Factors or other model comparison metrics. The choice of the specific metric depends on the characteristics of the models and the available computational resources.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../parts/implementing-bayes-theorem/basic-implementation.html" class="pagination-link" aria-label="Basic Implementation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Basic Implementation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../parts/implementing-bayes-theorem/discrete-probability-examples.html" class="pagination-link" aria-label="Introduction to Discrete Probability">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Introduction to Discrete Probability</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>